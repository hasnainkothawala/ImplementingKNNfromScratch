{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbours : Regression  Problem\n",
    "\n",
    "## Part 3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Part 3-A - \n",
    "* **Modify the distance weighted KNN code in PART 2 to solve a Regression Problem.And generate accuracy using R^2 method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Accuracy for Regressor =85.06560730414083\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class KNearestNeighbours:\n",
    "    def __init__(self, __trainingDataFile, __testDataFile):\n",
    "        self.weight = 10000\n",
    "        self.trainingDataFile = __trainingDataFile\n",
    "        self.testDataFile = __testDataFile\n",
    "        self.trainingData = np.array([])\n",
    "        self.testData = np.array([])\n",
    "        self.euclideanDistances = np.array([])\n",
    "        self.euclideanDistancesSorted = np.array([])\n",
    "        self.readInstances()\n",
    "\n",
    "    def readInstances(self):\n",
    "\n",
    "        self.trainingData = np.genfromtxt(self.trainingDataFile, delimiter=',', dtype=float)\n",
    "        self.testData = np.genfromtxt(self.testDataFile, delimiter=',', dtype=float)\n",
    "\n",
    "    def viewData(self):\n",
    "        self.updateDistances()\n",
    "        \n",
    "        \n",
    "    '''Calculates the distance between each training set instance and Target Test Instance  '''     \n",
    "    def calculateDistances(self, trainingInstancesMatrix, singlQueryPoint):\n",
    "        data = np.sqrt(np.sum((trainingInstancesMatrix - singlQueryPoint) ** 2, axis=1))\n",
    "        sorted_data = np.argsort(data)\n",
    "        return data, sorted_data\n",
    "\n",
    "    def updateDistances(self):\n",
    "        distances = []\n",
    "        sortedDistances = []\n",
    "        for i in range(0, np.shape(self.testData)[0]):\n",
    "            d, sd = self.calculateDistances(self.trainingData[:, :-1], self.testData[i, :-1])\n",
    "            distances.append(d)\n",
    "            sortedDistances.append(sd)\n",
    "            i += 1\n",
    "        self.euclideanDistances = np.array(distances)\n",
    "        self.euclideanDistancesSorted = np.array(sortedDistances)\n",
    "\n",
    "    '''Predict the value for each test instance'''\n",
    "    def generate_pred_for_regression_problem(self, results, euclidean_distance_of_neighbours):\n",
    "\n",
    "        invsquared_eucl_distance_bet_neighbours = 1 / np.square(euclidean_distance_of_neighbours)\n",
    "\n",
    "        predicted_value = np.sum(invsquared_eucl_distance_bet_neighbours * results) / np.sum(\n",
    "            invsquared_eucl_distance_bet_neighbours)\n",
    "        return predicted_value\n",
    "\n",
    "    '''Calculate the accuracy based on the R^2 method'''\n",
    "    def calculate_accuracy_for_Reg_prob(self, expected_results, predicted_results):\n",
    "\n",
    "        num = np.sum(np.square(predicted_results - expected_results))\n",
    "        deno = np.sum(np.square(np.average(expected_results) - expected_results))\n",
    "        final_accuracy = 1 - (num / deno)\n",
    "        return final_accuracy * 100\n",
    "\n",
    "'''**********************************************Do your Configurations Here *******************************************************************************'''\n",
    "kNearestNeighbours = KNearestNeighbours(\"data/regression/trainingData.csv\", \"data/regression/testData.csv\")\n",
    "kNearestNeighbours.viewData()\n",
    "'''**********************************************************************************************************************************************************'''\n",
    "# Select the number of neighbours\n",
    "k_list = range(1, 50)\n",
    "accuracy_list = []\n",
    "for k in k_list:\n",
    "\n",
    "    '''where the prediction result of each test instance will be stored'''\n",
    "    predicted_results = []\n",
    "    predicted_results_for_Reg_problems = []\n",
    "\n",
    "    '''Find the euclidean distance from each instance in test data and find the nearest train instances'''\n",
    "    for indexToBe_searched in range(np.shape(kNearestNeighbours.testData)[0]):\n",
    "        list_of_neighbours = kNearestNeighbours.euclideanDistancesSorted[indexToBe_searched][:k]\n",
    "        results = []\n",
    "        euclidean_distance_of_neighbours = []\n",
    "        for neighbour in list_of_neighbours:\n",
    "            result = kNearestNeighbours.trainingData[neighbour][-1:]\n",
    "\n",
    "            '''Find the distances between the target instance and the neighbours'''\n",
    "            euclidean_distance_of_neighbour = kNearestNeighbours.euclideanDistances[indexToBe_searched][neighbour]\n",
    "\n",
    "            '''Find the result for each neighbour'''\n",
    "            results.append(float(result))\n",
    "\n",
    "            euclidean_distance_of_neighbours.append(float(euclidean_distance_of_neighbour))\n",
    "\n",
    "        '''predict the result based on majority'''\n",
    "        predicted_results_for_Reg_problems.append(\n",
    "            [kNearestNeighbours.generate_pred_for_regression_problem(np.array(results), np.array(euclidean_distance_of_neighbours))])\n",
    "\n",
    "    '''Append the obtained prediction results to the test data for convenience'''\n",
    "    final_test_result = np.append(kNearestNeighbours.testData, predicted_results_for_Reg_problems, axis=1)\n",
    "    \n",
    "    '''Calculating the accracy'''\n",
    "    accuracy_for_Reg_prob = kNearestNeighbours.calculate_accuracy_for_Reg_prob(final_test_result[:, [-2]], final_test_result[:, [-1]])\n",
    "    accuracy_list.append(accuracy_for_Reg_prob)\n",
    "print('Max Accuracy for Regressor ={}'.format(max(accuracy_list)))\n",
    "\n",
    "'''Plotting the accuracy of the Regressor over multiple value of K '''\n",
    "plt.plot(accuracy_list)\n",
    "plt.xlabel('number of neighbours')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Accuracy of KNN Regressor  over k=[1:50]')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Below is the performance of The KNN regressor over k from 1 to 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dropbox.com/s/mpua9zuorqk0ub6/performance_KNN_regressor.png?raw=1\" alt=\"data1\" border=\"0\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 3-B \n",
    "* Explain why equal contribution from Irrelavant or Insignificant variable might cause a Negative impact on the performance of KNN and ways to counter it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  While working with KNN or any other machine learning algorithm it is important that the data is pre processed.\n",
    "Below are the two very important acpects of pre processing.\n",
    "    * Standarization:\n",
    "    * Normalization:\n",
    "\n",
    "* The above two become very critical while implementing KNN algorithm using Euclidean Distance. Below is the formula which is used for calculating Euclidean distance.\n",
    "\n",
    "* **What happens here ?**\n",
    "    * Lets us say every instance in your training and test set as 10 features.All you have to do it to calcualte the distance between Instance1(feature1) and Instance2(feature1) and so on ,for every feature in both the instances.\n",
    "    \n",
    "    * It is quite possible that some of the features in your data might be statistically very significant however some are not very significant.\n",
    "    \n",
    "    * However , Euclidean distance assumes that each feature in your data set is statistically equally important.This has its own ramifications, in the predicted class these statiscally insignnificant features get greater representation while determining the final predicated value(assuming we are solving a regression problem).\n",
    "    \n",
    "    \n",
    " \n",
    "* How to address this ?\n",
    "    * Firstly **standarize** the data to turn the data in to **guassian distribution.**\n",
    "    \n",
    "    * Secondly, **normalize** the data in **between a 0-1 scale** so that the larger numbers do not dominate the smaller ones.    eg. So that Salary does not dominate height in cms\n",
    "    \n",
    "    * Thirdly,it is now important to identify the staistically sihgnificant and statiscally insignificant features.\n",
    "    * **This can be done using **Backward Elimination** technique.**\n",
    "    \n",
    "* Backward Elimination.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Standardization.**\n",
    "    * Standardization is the process of rescaling the features so that they will have Guassian Distribution                     with mean=0 and standard deviation=1\n",
    "      calculated as :\n",
    "                   new value = feature-mean/standard deviation\n",
    "\n",
    "* **Normalization**\n",
    "    * Normalization is also called as min-max scaling.Where in also the features are converted into a range of 0  to 1 (sometimes -1 to 1 ) \n",
    "    * **Drawback**: Normalization is sensitive to outliers. So outliers must be removed before applying normalization.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8480139294676208"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Below is the code for standardization'''\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "train = pd.read_csv(\"data/regression/trainingData.csv\",delimiter=',',header= None)  # load train data\n",
    "test = pd.read_csv(\"data/regression/testData.csv\",delimiter=',',header= None)  # load test data\n",
    "X_train=train.iloc[:,:-1]\n",
    "y_train=train.iloc[:,-1]\n",
    "X_test=test.iloc[:,:-1]\n",
    "y_test=test.iloc[:,-1]\n",
    "\n",
    "'''Standarize the features in training and test set'''\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = KNeighborsRegressor(n_neighbors=10, n_jobs=4)\n",
    "model.fit(X_train, y_train)\n",
    "predict=model.predict(X_test)\n",
    "r2_score(y_test,predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below Methods can be used to eliminate statistically  insignificant features that influence the results.\n",
    "\n",
    "1. Kselectbest\n",
    "2. Backward Elimination\n",
    "\n",
    "We shall discuss **Backward Elimination** as a way ahead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Backward Elimination**\n",
    "\n",
    "* it a process of eliminating the features that are reported to be beyond the pre dicided bench mark(P value)\n",
    "\n",
    "* What is **p-value**?\n",
    "     This number defines how probable is it to not get the next result close to the current one.This video clearly explains \n",
    "    the concept.Basically it shows the level of confidence you have for that result to fail. The lesser the better.\n",
    "    \n",
    "* **Backward eliminnation in 4 simple steps:**\n",
    "        1.Select a significance level(p-value=5)\n",
    "        2.Fit a model with all features.\n",
    "        3.Consider the feature with higest p value.\n",
    "        4.Eliminate that feature.\n",
    "        5.Fit the modelwith the new features.Continue until all features are below the p value.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Below is the code for Backward Elimination\n",
    "    * Below OLS[Ordinary Least Square] can be used to evaluate the accuracy using the summary method and repeated untill all the variables above the p value are eliminated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                     12   R-squared:                       0.001\n",
      "Model:                            OLS   Adj. R-squared:                 -0.000\n",
      "Method:                 Least Squares   F-statistic:                    0.8566\n",
      "Date:                Thu, 12 Dec 2019   Prob (F-statistic):              0.510\n",
      "Time:                        15:33:12   Log-Likelihood:                -41899.\n",
      "No. Observations:                6400   AIC:                         8.381e+04\n",
      "Df Residuals:                    6394   BIC:                         8.385e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.1885      2.110     -0.089      0.929      -4.324       3.947\n",
      "x1             0.8293      2.131      0.389      0.697      -3.348       5.007\n",
      "x2            -0.2958      2.120     -0.140      0.889      -4.451       3.859\n",
      "x3            -3.8152      2.093     -1.823      0.068      -7.918       0.287\n",
      "x4             1.0195      2.091      0.488      0.626      -3.079       5.118\n",
      "x5             1.6203      2.092      0.774      0.439      -2.481       5.721\n",
      "==============================================================================\n",
      "Omnibus:                        0.535   Durbin-Watson:                   1.972\n",
      "Prob(Omnibus):                  0.765   Jarque-Bera (JB):                0.498\n",
      "Skew:                           0.017   Prob(JB):                        0.780\n",
      "Kurtosis:                       3.026   Cond. No.                         1.04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "train = pd.read_csv(\"data/regression/trainingData.csv\",delimiter=',',header= None)  # load train data\n",
    "test = pd.read_csv(\"data/regression/testData.csv\",delimiter=',',header= None)  # load test data\n",
    "X_train=train.iloc[:,:-1]\n",
    "y_train=train.iloc[:,-1]\n",
    "X_test=test.iloc[:,:-1]\n",
    "y_test=test.iloc[:,-1]\n",
    "model = KNeighborsRegressor(n_neighbors=10, n_jobs=4)\n",
    "model.fit(X_train, y_train)\n",
    "predict=model.predict(X_test)\n",
    "r2_score(y_test,predict)\n",
    "\n",
    "import numpy as np\n",
    "X_train = np.append (arr=np.ones([X_train.shape[0],1]).astype(int), values = X_train, axis = 1)\n",
    "\n",
    "import statsmodels.formula.api as sm\n",
    "X_opt = [0,1,2,3,4,6]\n",
    "regressor = sm.OLS(y_train, X_train[:,X_opt]).fit()\n",
    "print(regressor.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataframe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-fa9b653918f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dataframe' is not defined"
     ]
    }
   ],
   "source": [
    "dataframe(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                     12   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.000\n",
      "Method:                 Least Squares   F-statistic:                    0.2397\n",
      "Date:                Thu, 12 Dec 2019   Prob (F-statistic):              0.916\n",
      "Time:                        15:33:16   Log-Likelihood:                -41900.\n",
      "No. Observations:                6400   AIC:                         8.381e+04\n",
      "Df Residuals:                    6395   BIC:                         8.384e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.2330      2.110     -0.110      0.912      -4.369       3.903\n",
      "x1             0.8016      2.131      0.376      0.707      -3.377       4.980\n",
      "x2            -0.2158      2.120     -0.102      0.919      -4.371       3.939\n",
      "x3             1.0203      2.091      0.488      0.626      -3.079       5.120\n",
      "x4             1.5658      2.092      0.748      0.454      -2.536       5.667\n",
      "==============================================================================\n",
      "Omnibus:                        0.524   Durbin-Watson:                   1.971\n",
      "Prob(Omnibus):                  0.770   Jarque-Bera (JB):                0.488\n",
      "Skew:                           0.018   Prob(JB):                        0.783\n",
      "Kurtosis:                       3.024   Cond. No.                         1.04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "X_opt_new = [0,1,2,4,6]\n",
    "regressor = sm.OLS(y_train, X_train[:,X_opt_new]).fit()\n",
    "print(regressor.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'(slice(None, None, None), [0, 1, 2, 4, 6])' is an invalid key",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-b78ff1fdc255>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_opt_new\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpredict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_opt_new\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2926\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2927\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2655\u001b[0m                                  'backfill or nearest lookups')\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, None, None), [0, 1, 2, 4, 6])' is an invalid key"
     ]
    }
   ],
   "source": [
    "model = KNeighborsRegressor(n_neighbors=10, n_jobs=4)\n",
    "model.fit(X_train[:,X_opt_new], y_train)\n",
    "predict=model.predict(X_test[:,X_opt_new])\n",
    "r2_score(y_test,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
